# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/indexers.FaceRecognitionModel.ipynb (unless otherwise specified).

__all__ = ['arcface_r100_v1', 'retinaface_r50_v1', 'RETINAFACE_URL', 'ARCFACE_URL', 'FaceEmbeddingModel']

# Cell
from ...data.schema import *
from ...data.basic import *
from ...data.itembase import *
from ...pod.client import PodClient
from ..indexer import IndexerBase, get_indexer_run_data, IndexerData, test_registration
from .. import *
from ...imports import *
from .photo import *
from fastprogress.fastprogress import progress_bar

# Cell
from insightface.model_zoo.face_recognition import FaceRecognition
from insightface.model_zoo.face_detection import FaceDetector

# Cell
# hide
RETINAFACE_URL = f"{MEMRI_S3}/retinaface_r50_v1.zip"
ARCFACE_URL    = f"{MEMRI_S3}/arcface_r100_v1.zip"

def arcface_r100_v1():
    zipfile = MODEL_DIR / "arcface_r100_v1.zip"
    download_file(ARCFACE_URL, zipfile)
    unzipped = zipfile.with_suffix("")
    if not (unzipped / "model-symbol.json").exists(): unzip(zipfile, unzipped)
    params_file = str(unzipped / "model-0000.params")
    return FaceRecognition("r100_v1", True, params_file)

def retinaface_r50_v1():
    zipfile = MODEL_DIR / "retinaface_r50_v1.zip"
    download_file(RETINAFACE_URL, zipfile)
    unzipped = zipfile.with_suffix("")
    if not (unzipped / "R50-symbol.json").exists(): unzip(zipfile, unzipped)
    params_file = str(unzipped / "R50-0000.params")
    return FaceDetector(params_file, rac="net3")

# Cell
class FaceEmbeddingModel():
    """Recognizes photos from faces."""
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.recognition_model = arcface_r100_v1()
        self.recognition_model.prepare(-1);
        self.detection_model = retinaface_r50_v1()
        self.detection_model.prepare(-1);

    def compare(self, img1, img2):
        sim = round(float(self.recognition_model.compute_sim(img1, img2)), 2)
        return sim

    def predict_boundingboxes(self, iphoto):
        boxes, landmarks = self.detection_model.detect(iphoto.data)
        return boxes, landmarks

    def get_embedding(self, img, normalized=True):
        x = img.data if isinstance(img, IPhoto) else img
        return self.recognition_model.get_embedding(x).flatten()

    def get_crops(self, photos):
        crop_photos = []
        for i, photo in enumerate(progress_bar(photos)):
            boxes, landmarks = self.predict_boundingboxes(photo)
            crop_photos += [IPhoto.from_np(c) for c in photo.get_crops(boxes, landmarks)]
        return crop_photos