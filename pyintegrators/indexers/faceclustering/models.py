# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/indexers.FaceClusteringIndexer.Models.ipynb (unless otherwise specified).

__all__ = ['MeanAggregator', 'GraphConv', 'GCN_V', 'GCNVDataset', 'FaceClusteringModel']

# Cell
from integrators.indexers.faceclustering.utils import *
from integrators.indexers.facerecognition.model import *
from integrators.indexers.facerecognition.photo import *
from integrators.data.basic import *

from collections import Counter
from pathlib import Path
from mmcv.runner import load_checkpoint
from fastprogress.fastprogress import progress_bar
from torch.nn import init

import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import scipy.sparse as sp
import cv2, os, torch

# Cell
# hide
class MeanAggregator(nn.Module):
    def __init__(self):
        super(MeanAggregator, self).__init__()

    def forward(self, features, A):
        return torch.spmm(A, features)

class GraphConv(nn.Module):
    def __init__(self, in_dim, out_dim, agg, dropout=0):
        super(GraphConv, self).__init__()
        self.in_dim = in_dim
        self.out_dim = out_dim
        self.weight = nn.Parameter(torch.FloatTensor(in_dim * 2, out_dim))
        self.bias = nn.Parameter(torch.FloatTensor(out_dim))
        init.xavier_uniform_(self.weight)
        init.constant_(self.bias, 0)
        self.agg = agg()
        self.dropout = dropout

    def forward(self, features, A):
        feat_dim = features.shape[-1]
        assert (feat_dim == self.in_dim)
        agg_feats = self.agg(features, A)
        cat_feats = torch.cat([features, agg_feats], dim=-1)
        out = torch.einsum('nd,df->nf', (cat_feats, self.weight))
        out = F.relu(out + self.bias)
        return out

# Cell
# hide
class GCN_V(nn.Module):
    def __init__(self, feature_dim, nhid, nclass, dropout=0):
        super(GCN_V, self).__init__()
        self.conv1 = GraphConv(feature_dim, nhid, MeanAggregator, dropout)
        self.nclass = nclass
        self.classifier = nn.Sequential(nn.Linear(nhid, nhid),
                                        nn.PReLU(nhid),
                                        nn.Linear(nhid, self.nclass))
        self.loss = torch.nn.MSELoss()

    def forward(self, data):
        x, adj = data[0], data[1]
        x = self.conv1(x, adj)
        pred = self.classifier(x).view(-1)
        return pred

# Cell
# hide
class GCNVDataset(object):
    def __init__(self, features, label_path=None, k=80, feature_dim=256, is_norm_feat=True, th_sim=0.0,
                 max_conn=1, conf_metric="s_nbr", eval_interim=True):
        self.inst_num, self.feature_dim = features.shape
        self.k = k
        self.is_norm_feat = is_norm_feat
        self.th_sim = th_sim
        self.max_conn = max_conn
        self.conf_metric = conf_metric
        self.features = l2norm(features)
        self.size = 1 # take the entire graph as input

        # build knns and convert to (dists, nbrs)
        knns = build_knns("./data/knns/part1_test_small", self.features, "faiss", k, is_rebuild=True)
        self.dists, self.nbrs = knns2ordered_nbrs(knns)

        # build symmetric adjacency matrix
        adj = fast_knns2spmat(knns, k, th_sim, use_sim=True)
        self.adj = row_normalize(build_symmetric_adj(adj, self_loop=True))

    def __len__(self):
        return self.size

# Cell
class FaceClusteringModel():
    model_fname = "pretrained_gcn_v_ms1m.pth"
    model_path = MODEL_DIR / model_fname
    model_s3_url = f"{MEMRI_S3}/{model_fname}"

    def __init__(self, tau=0.4, *args, **kwargs):
        # tau used in the paper=0.65
        self.tau=tau
        self.rec_model = FaceEmbeddingModel()
        self.clustering_model = GCN_V(feature_dim=256, nhid=512, nclass=1, dropout=0.0)
        download_file(self.model_s3_url, self.model_path)
        load_checkpoint(self.clustering_model, str(self.model_path), map_location="cpu", strict=True);
        self.clustering_model.eval()

    def get_cluster_labels(self, features):
        dataset = GCNVDataset(features)
        features = torch.FloatTensor(dataset.features)
        adj = sparse_mx_to_torch_sparse_tensor(dataset.adj)
        confidences = self.clustering_model((features, adj)).detach().numpy()
        clusters = confidence2clusters(confidences, dists=dataset.dists,
                                       nbrs=dataset.nbrs, tau=self.tau)
        return clusters

    def run(self, photos):
        crop_photos = self.rec_model.get_crops(photos)
        for c in progress_bar(crop_photos): c.embedding = self.rec_model.get_embedding(c)
        crop_embeddings = np.stack([x.embedding[256:] for x in crop_photos])
        cluster_labels = self.get_cluster_labels(crop_embeddings)
        return crop_photos, cluster_labels