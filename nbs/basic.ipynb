{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from integrators.imports import *\n",
    "from urllib.request import urlretrieve\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from fastai.data.external import download_url\n",
    "from fastai.basics import progress_bar\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "Path.ls = lambda x: list(x.iterdir())\n",
    "PYI_HOME = Path.cwd().parent\n",
    "PYI_TESTDATA = PYI_HOME / \"test\" / \"data\"\n",
    "HOME_DIR = Path.home()\n",
    "MEMRI_DIR = HOME_DIR / \".memri\" \n",
    "MODEL_DIR =  MEMRI_DIR / \"models\"\n",
    "MEMRI_S3 = \"https://memri.s3-eu-west-1.amazonaws.com\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def read_file(path):\n",
    "    return open(path, \"r\").read()\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path) as json_file:\n",
    "        return json.load(json_file)\n",
    "\n",
    "def write_json(obj, fname):\n",
    "    with open(fname, 'w') as file_out:\n",
    "        json.dump(obj , file_out)\n",
    "        \n",
    "        \n",
    "def write_jsonl(objs, fname):\n",
    "    with open(fname, 'w') as file_out:\n",
    "        for o in objs:\n",
    "            json.dump(o, file_out)\n",
    "            file_out.write('\\n')\n",
    "\n",
    "def download_file(url, output_path): \n",
    "    if not Path(output_path).exists():\n",
    "        output_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "        print(f\"downloading {url}\", flush=True)\n",
    "        \n",
    "        # this may look overly complicated, but we want the system to first completely download and then write\n",
    "        # , to prevent caching issues.\n",
    "        response = requests.get(url, stream=True)\n",
    "        total_length = response.headers.get('content-length')\n",
    "        if total_length is None: # no content length header\n",
    "            res = response.content\n",
    "            with open(output_path, \"wb\") as f:\n",
    "                f.write(res)\n",
    "        else:\n",
    "            dl = 0\n",
    "            total_length = int(total_length)\n",
    "            pbar = progress_bar(range(total_length), leave=False)\n",
    "            pbar.update(0)\n",
    "            res = b''\n",
    "            for data in response.iter_content(chunk_size=1024*1024):\n",
    "                dl += len(data)\n",
    "                pbar.update(dl)\n",
    "                res += data\n",
    "            with open(output_path, \"wb\") as f:\n",
    "                f.write(res)\n",
    "        \n",
    "def unzip(f, dest):\n",
    "    with zipfile.ZipFile(str(f)) as zf:\n",
    "        zf.extractall(str(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "URL_REGEX = r'\\b((?:https?://)?(?:(?:www\\.)?(?:[\\da-z\\.-]+)\\.(?:[a-z]{2,6})|(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)|(?:(?:[0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|(?:[0-9a-fA-F]{1,4}:){1,7}:|(?:[0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|(?:[0-9a-fA-F]{1,4}:){1,5}(?::[0-9a-fA-F]{1,4}){1,2}|(?:[0-9a-fA-F]{1,4}:){1,4}(?::[0-9a-fA-F]{1,4}){1,3}|(?:[0-9a-fA-F]{1,4}:){1,3}(?::[0-9a-fA-F]{1,4}){1,4}|(?:[0-9a-fA-F]{1,4}:){1,2}(?::[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:(?:(?::[0-9a-fA-F]{1,4}){1,6})|:(?:(?::[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(?::[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(?:ffff(?::0{1,4}){0,1}:){0,1}(?:(?:25[0-5]|(?:2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(?:25[0-5]|(?:2[0-4]|1{0,1}[0-9]){0,1}[0-9])|(?:[0-9a-fA-F]{1,4}:){1,4}:(?:(?:25[0-5]|(?:2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(?:25[0-5]|(?:2[0-4]|1{0,1}[0-9]){0,1}[0-9])))(?::[0-9]{1,4}|[1-5][0-9]{4}|6[0-4][0-9]{3}|65[0-4][0-9]{2}|655[0-2][0-9]|6553[0-5])?(?:/[\\w\\.-]*)*/?)\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from bs4 import BeautifulSoup\n",
    "EMAIL = \"XX_EMAIL\"\n",
    "URL   = \"XX_URL\"\n",
    "\n",
    "def strip_html(html):\n",
    "    soup = BeautifulSoup(html, features=\"lxml\")\n",
    "    res = soup.get_text()\n",
    "    return res\n",
    "\n",
    "def replace_urls(s):\n",
    "    return re.sub(URL_REGEX, EMAIL, s)\n",
    "    \n",
    "def replace_emails(s):\n",
    "    return re.sub(r'[\\w\\.-]+@[\\w\\.-]+', URL, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted basic.ipynb.\n",
      "Converted importers.EmailImporter.ipynb.\n",
      "Converted importers.Importer.ipynb.\n",
      "Converted importers.util.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted indexers.FaceClusteringIndexer.Models.ipynb.\n",
      "Converted indexers.FaceClusteringIndexer.Utils.ipynb.\n",
      "Converted indexers.FaceClusteringIndexer.indexer.ipynb.\n",
      "Converted indexers.FaceRecognitionModel.ipynb.\n",
      "Converted indexers.FacerecognitionIndexer.Photo.ipynb.\n",
      "Converted indexers.GeoIndexer.ipynb.\n",
      "Converted indexers.NoteListIndexer.NoteList.ipynb.\n",
      "Converted indexers.NoteListIndexer.Parser.ipynb.\n",
      "Converted indexers.NoteListIndexer.ipynb.\n",
      "Converted indexers.NoteListIndexer.util.ipynb.\n",
      "Converted indexers.indexer.ipynb.\n",
      "Converted itembase.ipynb.\n",
      "Converted pod.client.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
