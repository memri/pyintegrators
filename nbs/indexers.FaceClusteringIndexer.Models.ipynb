{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# default_exp indexers.faceclustering.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from integrators.indexers.faceclustering.utils import *\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from mmcv.runner import load_checkpoint\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import cv2\n",
    "import os\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from torch.nn import init\n",
    "\n",
    "class MeanAggregator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanAggregator, self).__init__()\n",
    "\n",
    "    def forward(self, features, A):\n",
    "        if features.dim() == 2:\n",
    "            x = torch.spmm(A, features)\n",
    "        elif features.dim() == 3:\n",
    "            x = torch.bmm(A, features)\n",
    "        else:\n",
    "            raise RuntimeError('the dimension of features should be 2 or 3')\n",
    "        return x\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, agg, dropout=0):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_dim * 2, out_dim))\n",
    "        self.bias = nn.Parameter(torch.FloatTensor(out_dim))\n",
    "        init.xavier_uniform_(self.weight)\n",
    "        init.constant_(self.bias, 0)\n",
    "        self.agg = agg()\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, features, A):\n",
    "        feat_dim = features.shape[-1]\n",
    "        assert (feat_dim == self.in_dim)\n",
    "        agg_feats = self.agg(features, A)\n",
    "        cat_feats = torch.cat([features, agg_feats], dim=-1)\n",
    "        if features.dim() == 2:\n",
    "            op = 'nd,df->nf'\n",
    "        elif features.dim() == 3:\n",
    "            op = 'bnd,df->bnf'\n",
    "        else:\n",
    "            raise RuntimeError('the dimension of features should be 2 or 3')\n",
    "        out = torch.einsum(op, (cat_feats, self.weight))\n",
    "        out = F.relu(out + self.bias)\n",
    "        if self.dropout > 0:\n",
    "            out = F.dropout(out, self.dropout, training=self.training)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class GCN_V(nn.Module):\n",
    "    def __init__(self, feature_dim, nhid, nclass, dropout=0):\n",
    "        super(GCN_V, self).__init__()\n",
    "        self.conv1 = GraphConv(feature_dim, nhid, MeanAggregator, dropout)\n",
    "\n",
    "        self.nclass = nclass\n",
    "        self.classifier = nn.Sequential(nn.Linear(nhid, nhid), nn.PReLU(nhid),\n",
    "                                        nn.Linear(nhid, self.nclass))\n",
    "        self.loss = torch.nn.MSELoss()\n",
    "\n",
    "    def forward(self, data, output_feat=False, return_loss=False):\n",
    "        assert not output_feat or not return_loss\n",
    "        x, adj = data[0], data[1]\n",
    "        x = self.conv1(x, adj)\n",
    "        pred = self.classifier(x).view(-1)\n",
    "\n",
    "        if output_feat:\n",
    "            return pred, x\n",
    "\n",
    "        if return_loss:\n",
    "            label = data[2]\n",
    "            loss = self.loss(pred, label)\n",
    "            return pred, loss\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def l2norm(vec):\n",
    "    vec /= np.linalg.norm(vec, axis=1).reshape(-1, 1)\n",
    "    return vec\n",
    "\n",
    "\n",
    "class GCNVDataset(object):\n",
    "    def __init__(self, features, label_path=None, k=80, feature_dim=256, is_norm_feat=True, th_sim=0.0, \n",
    "                 max_conn=1, conf_metric=\"s_nbr\", eval_interim=True):\n",
    "        \n",
    "        self.inst_num, self.feature_dim = features.shape\n",
    "        self.k = k\n",
    "        self.is_norm_feat = is_norm_feat\n",
    "\n",
    "        self.th_sim = th_sim\n",
    "        self.max_conn = max_conn\n",
    "        self.conf_metric = conf_metric\n",
    "        self.features = l2norm(features)\n",
    "        self.size = 1 # take the entire graph as input\n",
    "            \n",
    "        knns = build_knns(\"./data/knns/part1_test_small\", self.features, \"faiss\", k, is_rebuild=True)\n",
    "\n",
    "        adj = fast_knns2spmat(knns, k, th_sim, use_sim=True)\n",
    "\n",
    "        # build symmetric adjacency matrix\n",
    "        self.adj = row_normalize(build_symmetric_adj(adj, self_loop=True))\n",
    "\n",
    "        # convert knns to (dists, nbrs)\n",
    "        self.dists, self.nbrs = knns2ordered_nbrs(knns)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ''' return the entire graph for training.\n",
    "        To accelerate training or cope with larger graph,\n",
    "        we can sample sub-graphs in this function.\n",
    "        '''\n",
    "\n",
    "        assert index == 0\n",
    "        return (self.features, self.adj_indices, self.adj_values,\n",
    "                self.adj_shape, self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
