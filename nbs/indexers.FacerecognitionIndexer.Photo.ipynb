{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# default_exp indexers.facerecognition.photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from integrators.data.schema import *\n",
    "from insightface.utils import face_align\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib import patches\n",
    "from matplotlib.collections import PatchCollection\n",
    "from numpy.linalg import norm\n",
    "from hashlib import sha256\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def show_images(images, cols = 3, titles = None):\n",
    "    image_list = [x.data for x in images] if isinstance(images[0], Photo) else images\n",
    "    assert((titles is None) or (len(image_list) == len(titles)))\n",
    "    n_images = len(image_list)\n",
    "    if titles is None: titles = [\"\" for i in range(1,n_images + 1)]\n",
    "    fig = plt.figure()\n",
    "    for n, (image, title) in enumerate(zip(image_list, titles)):\n",
    "        a = fig.add_subplot(int(np.ceil(n_images/float(cols))), cols , n + 1)\n",
    "        a.axis('off')\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(image[:,:,::-1])\n",
    "        a.set_title(title)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export  \n",
    "def get_size(img, maxsize):\n",
    "    s = img.shape\n",
    "    assert len(s) > 1\n",
    "    div = max(s) / maxsize\n",
    "    return (int(s[1]//div), int(s[0]//div))\n",
    "\n",
    "def resize(img, maxsize):\n",
    "    size = get_size(img, maxsize)\n",
    "    return cv2.resize(img, dsize=size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def get_height_width_channels(img):\n",
    "    s = img.shape\n",
    "    if len(s) == 2: return s[0], s[1], 1\n",
    "    else: return img.shape\n",
    "\n",
    "class IPhoto(Photo):\n",
    "    \n",
    "    def __init__(self, data=None, embedding=None,path=None, *args, **kwargs):\n",
    "        self.private = [\"data\", \"embedding\", \"path\"]\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.data=data\n",
    "        self.embedding=embedding\n",
    "        self.path=path\n",
    "\n",
    "    def show(self):\n",
    "        fig,ax = plt.subplots(1)\n",
    "        fig.set_figheight(15)\n",
    "        fig.set_figwidth(15)\n",
    "        ax.axis('off')\n",
    "        imshow(self.data[:,:,::-1])\n",
    "        \n",
    "    def draw_boxes(self, boxes):\n",
    "        print(f\"Plotting {len(boxes)} face boundingboxes\")\n",
    "        fig,ax = plt.subplots(1)\n",
    "        fig.set_figheight(15)\n",
    "        fig.set_figwidth(15)\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Display the image\n",
    "        ax.imshow(self.data[:,:,::-1])\n",
    "\n",
    "        ps = []\n",
    "        # Create a Rectangle patch\n",
    "        for b in boxes:\n",
    "            rect = self.box_to_rect(b)\n",
    "            ax.add_patch(rect)    \n",
    "            ps.append(rect)\n",
    "        plt.show()\n",
    "        \n",
    "    def get_crops(self, boxes, landmarks=None):\n",
    "        crops = []\n",
    "        if landmarks is None:\n",
    "            print(\"you are getting unnormalized crops, which are lower quality for recognition\")\n",
    "        for i, b in enumerate(boxes):      \n",
    "            b = [max(0, int(x)) for x in b]\n",
    "            \n",
    "            if landmarks is not None:\n",
    "                crop = face_align.norm_crop(self.data, landmark = landmarks[i])\n",
    "            else:\n",
    "                crop = self.data[b[1]:b[3], b[0]:b[2], :]\n",
    "            crops.append(crop)\n",
    "        return crops\n",
    "    \n",
    "    def plot_crops(self, boxes, landmarks=None):\n",
    "        crops = self.get_crops(boxes, landmarks)\n",
    "        show_images(crops, cols=3)        \n",
    "        \n",
    "    @classmethod    \n",
    "    def from_path(cls, path, size=None):\n",
    "        data = cv2.imread(str(path))\n",
    "        if size is not None: data = resize(data, size)\n",
    "        h,w,c = get_height_width_channels(data)\n",
    "        res = cls(data=data, path=path, height=h, width=w, channels=c)\n",
    "        file = File.from_data(sha256=sha256(data.tobytes()).hexdigest())\n",
    "        res.add_edge(\"file\", file)\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    def from_np(cls, data):\n",
    "        h,w,c = get_height_width_channels(data)\n",
    "        res = cls(data=data, height=h, width=w, channels=c)\n",
    "        file = File.from_data(sha256=sha256(data.tobytes()).hexdigest())\n",
    "        res.add_edge(\"file\", file)\n",
    "        return res\n",
    "    \n",
    "    @staticmethod\n",
    "    def box_to_rect(box):\n",
    "        x = box[0]\n",
    "        y = box[1]\n",
    "        w = box[2]-box[0]\n",
    "        h = box[3]-box[1]\n",
    "        return patches.Rectangle((x,y),w,h, linewidth=2,edgecolor='r',facecolor='none')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo = IPhoto.from_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted basic.ipynb.\n",
      "Converted importers.EmailImporter.ipynb.\n",
      "Converted importers.Importer.ipynb.\n",
      "Converted importers.util.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted indexers.FaceClusteringIndexer.Models.ipynb.\n",
      "Converted indexers.FaceClusteringIndexer.Utils.ipynb.\n",
      "Converted indexers.FaceClusteringIndexer.indexer.ipynb.\n",
      "Converted indexers.FaceRecognitionIndexer.ipynb.\n",
      "Converted indexers.FacerecognitionIndexer.Photo.ipynb.\n",
      "Converted indexers.GeoIndexer.ipynb.\n",
      "Converted indexers.NoteListIndexer.NoteList.ipynb.\n",
      "Converted indexers.NoteListIndexer.Parser.ipynb.\n",
      "Converted indexers.NoteListIndexer.ipynb.\n",
      "Converted indexers.NoteListIndexer.util.ipynb.\n",
      "Converted indexers.indexer.ipynb.\n",
      "Converted itembase.ipynb.\n",
      "Converted pod.client.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
