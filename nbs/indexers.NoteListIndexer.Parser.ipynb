{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# default_exp indexers.notelist.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import bs4\n",
    "import random\n",
    "from integrators.indexers.notelist.util import *\n",
    "from integrators.indexers.notelist.notelist import *\n",
    "from integrators.data.schema import *\n",
    "from integrators.data.basic import *\n",
    "from integrators.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "LISTTYPE_VERBS = [\"do\", \"read\", \"watch\", \"buy\", \"listen\"]\n",
    "LIST_PREFIXES = [\"to\", \"to-\", \"to \", \"\"]\n",
    "\n",
    "class HTMLListParser():\n",
    "    '''Extracts lists from HTML data, generated by an HTML text editor like evernote'''\n",
    "    \n",
    "    def __init__(self):        \n",
    "        self.single_item_list_patterns = [p+v for v in LISTTYPE_VERBS for p in LIST_PREFIXES]\n",
    "    \n",
    "    def get_html_lists(self, note, parsed):\n",
    "        html_lists = parsed.find_all(\"ul\", recursive=False) + parsed.find_all(\"ol\", recursive=False)\n",
    "        return [ULNoteList.from_data(title=None, content=str(x), textContent=x.get_text(),\n",
    "                                     note=note, span=get_span(x, parsed)) for x in html_lists]\n",
    "    \n",
    "    def get_lists(self, note):\n",
    "        \"\"\"Extracts lists from a note\"\"\"\n",
    "        parsed = bs4.BeautifulSoup(note.content, 'html.parser')\n",
    "        note.content=str(parsed)\n",
    "\n",
    "        all_lists = self.get_html_lists(note, parsed) + \\\n",
    "                    self.get_unformatted_lists(note, parsed)\n",
    "        for l in all_lists: note.add_edge(\"noteList\", l)\n",
    "\n",
    "        return all_lists\n",
    "    \n",
    "    def parse(self, x, tag=None):\n",
    "        if isinstance(x, bs4.BeautifulSoup): return x.find(tag) if tag is not None else x\n",
    "        elif isinstance(x, bs4.element.Tag): return x\n",
    "        else: \n",
    "            res =  bs4.BeautifulSoup(x, 'html.parser')\n",
    "            return res.find(tag) if tag is not None else res\n",
    "\n",
    "    def get_single_line_list(self, par):\n",
    "        \"\"\"Get single list lists. An example could be: '<strong>read</strong>: great book title'\"\"\"\n",
    "        par = self.parse(par, \"p\")\n",
    "        par_html = \"\".join(mapped(str, par.contents))\n",
    "        \n",
    "        pat = \"|\".join([f\"(<strong>|<em>|<u>)?{v}:? ?(</strong>|</em>|</u>)?:? ?\"\n",
    "                        for v in LISTTYPE_VERBS])\n",
    "        match = re.search(pat, par_html, re.IGNORECASE)\n",
    "        if match is None: return None, None\n",
    "        \n",
    "        title_html = match.group() if match is not None else None\n",
    "\n",
    "        if len(par.get_text()) > len(remove_html(title_html)) + 2:\n",
    "            title = match.group()\n",
    "            content = par_html[par_html.index(title) + len(title):]\n",
    "            return title, content\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "    def get_unformatted_lists(self, note, parsed):\n",
    "        \"\"\"retrieve lists without <ul></ul> tags. We have two options: \n",
    "                1) multiline lists prefixed with a title keyword (e.g. \"Buy:\" \"Read:\") \n",
    "                2) single element single line lists\"\"\"\n",
    "\n",
    "        parsed = parsed if parsed is not None else self.parse(note.content)\n",
    "        toplevel_paragraphs = parsed.find_all(\"p\", recursive=False)\n",
    "        res = []\n",
    "\n",
    "        for i, par in enumerate(toplevel_paragraphs):\n",
    "            if is_title(par):\n",
    "                # this extracts the lists that have a title and are not on a single line\n",
    "                items = trim_till_newline(toplevel_paragraphs[i+1:])\n",
    "                if len(items) == 0: continue\n",
    "                    \n",
    "                list_span  = Span.from_data(startIdx=get_span(title, parsed).startIdx,\n",
    "                                            endIdx=get_span(items[-1], parsed).endIdx)            \n",
    "\n",
    "                l = INoteList.from_data(note=note,span=list_span,\n",
    "                                        title=str(par.contents[0]),\n",
    "                                        content=\"\".join(mapped(str,items)),\n",
    "                                        itemSpan=[get_span(x, parsed) for x in items])                    \n",
    "                res.append(l)\n",
    "\n",
    "            else:\n",
    "                title, html_content = self.get_single_line_list(par)\n",
    "                if title is not None:\n",
    "                                                  \n",
    "                    span = get_span(str(par), parsed)\n",
    "                    \n",
    "                    \n",
    "                    itemSpans = [Span.from_data(startIdx=span.startIdx + len(str(title)),\n",
    "                                                endIdx=span.endIdx)]\n",
    "                    l = INoteList.from_data(note=note, title=title, content=str(html_content),\n",
    "                                            itemSpan=itemSpans, span=get_span(par, parsed)) \n",
    "                    res.append(l)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how this works for an example note. We start with a note that was imported from evernote as example and show its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note = INote.from_data(content=read_file(PYI_TESTDATA / \"notes\" / \"evernote\" / \"evernote-test-note-1.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div>\n",
      "    <div><br clear=\"none\" /></div>\n",
      "    <div><br clear=\"none\" /></div>\n",
      "    <ul>\n",
      "        <li>Buy groceries</li>\n",
      "        <li>Call john<br clear=\"none\" /></li>\n",
      "        <li>Do the taxes</li>\n",
      "        <li>Take out the trash</li>\n",
      "        <li>Reply to carls mail</li>\n",
      "    </ul>\n",
      "    <div><br clear=\"none\" /></div>\n",
      "    <ul>\n",
      "        <li>Buy groceries</li>\n",
      "        <li>Call john<ul>\n",
      "                <li>He r\n"
     ]
    }
   ],
   "source": [
    "print(note.content[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which corresponds to this when rendered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(HTML(note.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can parse these using the `HTMLListParser`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memri lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single line lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HTMLListParser()\n",
    "note = INote.from_data(content=read_file(PYI_TESTDATA / \"notes\" / \"memri\" / \"memri-test-note-3.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title, content = parser.get_single_line_list(\"<p>Buy: Toothpaste</p>\")\n",
    "test_eq(title, \"Buy: \"); test_eq(content, \"Toothpaste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title, content = parser.get_single_line_list(\"<p><strong>Read: </strong>The age of surveillance capitalism</p>\")\n",
    "test_eq(title, \"<strong>Read: </strong>\"); test_eq(content, \"The age of surveillance capitalism\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title, content = parser.get_single_line_list(\"<p>Watch: Parasite</p>\")\n",
    "test_eq(title, \"Watch: \"); test_eq(content, \"Parasite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title, content = parser.get_single_line_list(\"<p><u>Do</u>: The dishes</p>\")\n",
    "test_eq(title, \"<u>Do</u>: \"); test_eq(content, \"The dishes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = note.content\n",
    "parsed = bs4.BeautifulSoup(txt, 'html.parser')\n",
    "assert len(parser.get_unformatted_lists(note, parsed)) == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = parser.get_lists(note)\n",
    "assert len(lists) == 10\n",
    "# list0,list1,list2,list3,list4,list5,list6,list7,list8,list9 = lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ULNoteList # Untitled \n",
       " \n",
       " \n",
       " Buy groceries\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " Call john\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " Do the taxes\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " Take out the trash\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " Reply to carls mail\n",
       " \n",
       " \n",
       " ,\n",
       " ULNoteList # Untitled \n",
       " Buy groceries\n",
       " Do the taxes\n",
       " Take out the trash\n",
       " Reply to carls mail\n",
       " ,\n",
       " ULNoteList # Untitled \n",
       " Twenty one lessons for the 21st century\n",
       " Dreams from my Father\n",
       " ,\n",
       " (INoteList) # Buy:  \n",
       " Toothpaste\n",
       " ,\n",
       " (INoteList) # Read:  \n",
       " The age of surveillance capitalism\n",
       " ,\n",
       " (INoteList) # Watch:  \n",
       " Parasite\n",
       " ,\n",
       " (INoteList) # Do:  \n",
       " The dishes\n",
       " ,\n",
       " (INoteList) # Read \n",
       " <p>The Great Gastby</p><p>Alice’s Adventures in Wonderland</p>\n",
       " ,\n",
       " (INoteList) # Buy \n",
       " <p>Groceries</p><p>Shoes</p>\n",
       " ,\n",
       " (INoteList) # Read \n",
       " <p>The Great Gatsby</p><p>The Odyssey</p>\n",
       " ]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evernote lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HTMLListParser()\n",
    "note = INote.from_data(content=read_file(PYI_TESTDATA / \"notes\" / \"evernote\" / \"evernote-test-note-1.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists = parser.get_lists(note)\n",
    "# assert len(lists) == 10\n",
    "# list0,list1,list2,list3,list4,list5,list6,list7,list8,list9 = lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_eq(list0.get_items(), ['<li>Buy groceries</li>',\n",
    "#                              '<li>Call john<br clear=\"none\"/></li>',\n",
    "#                              '<li>Do the taxes</li>',\n",
    "#                              '<li>Take out the trash</li>',\n",
    "#                              '<li>Reply to carls mail</li>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_eq(list1.get_items(), ['<li>Buy groceries</li>',\n",
    "#                              '<li>Do the taxes</li>',\n",
    "#                              '<li>Take out the trash</li>',\n",
    "#                              '<li><br clear=\"none\"/></li>',\n",
    "#                              '<li>Reply to carls mail</li>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_eq(list2.get_items(), ['<li>Twenty one lessons for the 21st century</li>',\n",
    "#                             '<li>Dreams from my Father</li>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_eq(list3.title, '<strong>Buy</strong>: ')\n",
    "# test_eq(list3.get_items(), ['Toothpaste'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_eq(list4.title, '<em>Read</em>: ')\n",
    "# test_eq(list4.get_items(), ['The age of surveillance capitalism'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_eq(list5.title, 'Watch: ')\n",
    "# test_eq(list5.get_items(), ['Parasite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_eq(list6.title, '<u>Do</u>: ')\n",
    "# test_eq(list6.get_items(), ['The dishes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_eq(list7.title,'<strong>Read</strong><br clear=\"none\"/>')\n",
    "# test_eq(list7.get_items(), ['The Great Gatsby', \"Alice's Adventures in Wonderland\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_eq(list8.title,'<strong>Buy</strong><br clear=\"none\"/>')\n",
    "# test_eq(list8.get_items(), ['groceries', 'Shoes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_eq(list9.title,'Read')\n",
    "# test_eq(list9.get_items(), ['The Great Gatsby', 'The odyssey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HTMLListParser.get_lists\" class=\"doc_header\"><code>HTMLListParser.get_lists</code><a href=\"__main__.py#L17\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HTMLListParser.get_lists</code>(**`note`**)\n",
       "\n",
       "Extracts lists from a note"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HTMLListParser.get_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HTMLListParser.get_unformatted_lists\" class=\"doc_header\"><code>HTMLListParser.get_unformatted_lists</code><a href=\"__main__.py#L54\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HTMLListParser.get_unformatted_lists</code>(**`note`**, **`parsed`**)\n",
       "\n",
       "retrieve lists without <ul></ul> tags. We have two options: \n",
       "1) multiline lists prefixed with a title keyword (e.g. \"Buy:\" \"Read:\") \n",
       "2) single element single line lists"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HTMLListParser.get_unformatted_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HTMLListParser.get_single_line_list\" class=\"doc_header\"><code>HTMLListParser.get_single_line_list</code><a href=\"__main__.py#L35\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HTMLListParser.get_single_line_list</code>(**`par`**)\n",
       "\n",
       "Get single list lists. An example could be: '<strong>read</strong>: great book title'"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HTMLListParser.get_single_line_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted basic.ipynb.\n",
      "Converted importers.EmailImporter.ipynb.\n",
      "Converted importers.Importer.ipynb.\n",
      "Converted importers.util.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted indexers.FaceRecognitionIndexer.ipynb.\n",
      "Converted indexers.FacerecognitionIndexer.Photo.ipynb.\n",
      "Converted indexers.GeoIndexer.ipynb.\n",
      "Converted indexers.NoteListIndexer.NoteList.ipynb.\n",
      "Converted indexers.NoteListIndexer.Parser.ipynb.\n",
      "Converted indexers.NoteListIndexer.ipynb.\n",
      "Converted indexers.NoteListIndexer.util.ipynb.\n",
      "Converted indexers.indexer.ipynb.\n",
      "Converted itembase.ipynb.\n",
      "Converted pod.client.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
